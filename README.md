# terraform-aws-grafana

This module is created(based on base module [`dasmeta/grafana/onpremise`](https://github.com/dasmeta/terraform-onpremise-grafana)) to manage grafana stack components on aws eks
At this moment we support managing
- Grafana stack
  - grafana
  - prometheus
  - loki_stack(with promtail collector)
  - tempo
- Grafana Dashboard with `dashboard` submodule
- Grafana Alerts with `alerts` submodule
- Grafana Contact Points with `contact-points` submodule
- Grafana Notification Policies with `notifications` submodule

## Known issues
Grafana provider sometimes has issues with endpoints behind WAFs: https://github.com/grafana/terraform-provider-grafana/issues/1851


# Release important notes and upgrade guides
- <1.1.0 to >=1.1.0 brings several BREAKING changes which are described in terraform-onpremise-grafana module [<1.27.0 to >=1.27.0 upgrade guide](https://github.com/dasmeta/terraform-onpremise-grafana#:~:text=enable%20apply%20again-,%3C1.27.0%20to%20%3E%3D1.27.0,-In%20this%20release)

## example for dashboard
```hcl
module "this" {
  source  = "dasmeta/grafanav12/aws"
  # version = "x.y.z" # set version constraint when using the module to not have auto upgrade and possible breaks

  name         = "Test-dashboard"
  cluster_name = "eks-dev"

  application_dashboard = {
    rows : [
      { type : "block/sla", sla_ingress_type = "alb", load_balancer_arn = "load_balancer_arn", datasource_uid = "cloudwatch", region = "us-east-2" },
      { type : "block/alb_ingress", load_balancer_arn = "load_balancer_arn", region : "us-east-2" },
      { type : "block/service", name = "worker", show_err_logs = true },
      { type : "block/cloudwatch", region : "us-east-2" }
    ]
    data_source = {
      uid : "cloudwatch"
    }
    variables = [
      {
        "name" : "namespace",
        "options" : [
          {
            "value" : "prod"
          },
          {
            "selected" : true,
            "value" : "dev"
          }
        ],
      }
    ]
  }
  alerts = {
    rules = [
      {
        "datasource" : "prometheus",
        "equation" : "gt",
        "expr" : "avg(increase(nginx_ingress_controller_request_duration_seconds_sum[3m])) / 10",
        "folder_name" : "Nginx Alerts",
        "function" : "mean",
        "name" : "Latency P1",
        "labels" : {
          "priority" : "P1",
        }
        "threshold" : 3

        # we override no-data/exec-error state for this example/test only, it is supposed this values will not be set here so they get their default ones
        "no_data_state" : "OK"
        "exec_err_state" : "OK"
        # "exec_err_state" : "Alerting" # uncomment to trigger new alert
      },
      {
        "datasource" : "prometheus",
        "equation" : "gt",
        "expr" : "avg(increase(nginx_ingress_controller_request_duration_seconds_sum[3m])) / 10",
        "folder_name" : "Nginx Alerts",
        "function" : "mean",
        "name" : "Latency P2",
        "labels" : {
          "priority" : "P2",
        }
        "threshold" : 3

        # we override no-data/exec-error state for this example/test only, it is supposed this values will not be set here so they get their default ones
        "no_data_state" : "OK"
        "exec_err_state" : "OK"
        # "exec_err_state" : "Alerting" # uncomment to trigger new alert
      }
    ]
  }

  grafana = {

    resources = {
      request = {
        cpu = "1"
        mem = "1Gi"
      }
    }
    ingress = {
      type            = "alb"
      tls_enabled     = true
      public          = true
      alb_certificate = "cert_arn"

      hosts = ["grafana.example.com"]
      additional_annotations = {
        "alb.ingress.kubernetes.io/group.name" = "dev-ingress"
      }
    }


  }

  tempo = {
    enabled = true
  }

  loki_stack = {
    enabled = true

  }

  prometheus = {
    enabled = true
  }

  grafana_admin_password = "admin"
}
```

<!-- BEGINNING OF PRE-COMMIT-TERRAFORM DOCS HOOK -->
## Requirements

| Name | Version |
|------|---------|
| <a name="requirement_terraform"></a> [terraform](#requirement\_terraform) | ~> 1.3 |
| <a name="requirement_aws"></a> [aws](#requirement\_aws) | ~> 5.0 |
| <a name="requirement_deepmerge"></a> [deepmerge](#requirement\_deepmerge) | ~> 1.1 |
| <a name="requirement_grafana"></a> [grafana](#requirement\_grafana) | ~> 4.0 |
| <a name="requirement_helm"></a> [helm](#requirement\_helm) | ~> 2.4 |

## Providers

| Name | Version |
|------|---------|
| <a name="provider_aws"></a> [aws](#provider\_aws) | ~> 5.0 |
| <a name="provider_random"></a> [random](#provider\_random) | n/a |

## Modules

| Name | Source | Version |
|------|--------|---------|
| <a name="module_grafana_cloudwatch_role"></a> [grafana\_cloudwatch\_role](#module\_grafana\_cloudwatch\_role) | dasmeta/iam/aws//modules/role | 1.3.0 |
| <a name="module_loki_bucket"></a> [loki\_bucket](#module\_loki\_bucket) | dasmeta/s3/aws | 1.3.2 |
| <a name="module_s3_eks_role"></a> [s3\_eks\_role](#module\_s3\_eks\_role) | dasmeta/iam/aws//modules/role | 1.3.0 |
| <a name="module_tempo_bucket"></a> [tempo\_bucket](#module\_tempo\_bucket) | dasmeta/s3/aws | 1.3.2 |
| <a name="module_this"></a> [this](#module\_this) | dasmeta/grafana/onpremise | 1.27.7 |

## Resources

| Name | Type |
|------|------|
| [random_string.random](https://registry.terraform.io/providers/hashicorp/random/latest/docs/resources/string) | resource |
| [aws_caller_identity.current](https://registry.terraform.io/providers/hashicorp/aws/latest/docs/data-sources/caller_identity) | data source |
| [aws_eks_cluster.this](https://registry.terraform.io/providers/hashicorp/aws/latest/docs/data-sources/eks_cluster) | data source |
| [aws_region.current](https://registry.terraform.io/providers/hashicorp/aws/latest/docs/data-sources/region) | data source |

## Inputs

| Name | Description | Type | Default | Required |
|------|-------------|------|---------|:--------:|
| <a name="input_alerts"></a> [alerts](#input\_alerts) | Alerting configurations, NOTE: we have also option to create alert rules attached to dashboard widget blocks | <pre>object({<br/>    alert_interval_seconds  = optional(number, 10)       # The interval, in seconds, at which all rules in the group are evaluated. If a group contains many rules, the rules are evaluated sequentially<br/>    disable_provenance      = optional(bool, true)       # Allow modifying resources from other sources than Terraform or the Grafana API<br/>    create_folder           = optional(bool, false)      # whether to create folder to place app dashboard and alerts there, if folder with provided name exist already no need to create it again<br/>    folder_name             = optional(string, null)     # The folder name for dashboard, if not set it defaults to var.application_dashboard.folder_name<br/>    group                   = optional(string, "custom") # The alerts general group name<br/>    enable_message_template = optional(bool, true)       # Whether to enable the message template for the alerts<br/>    # Predefined annotations structure for all alerts<br/>    # These annotations will be applied to all alerts and can be overridden by rule-specific annotations<br/>    # Values provided here will also be available in notification templates<br/>    annotations = optional(object({<br/>      component    = optional(string, "") # Component or service name (e.g., "kubernetes", "database", "api")<br/>      owner        = optional(string, "") # Team or person responsible for the alert (e.g., "Platform Team", "DevOps")<br/>      issue_phrase = optional(string, "") # Brief description of the issue type (e.g., "Service Issue", "Infrastructure Alert")<br/>      impact       = optional(string, "") # Description of the impact (e.g., "Service degradation", "Complete outage")<br/>      runbook      = optional(string, "") # URL to runbook or documentation for resolving the issue<br/>      provider     = optional(string, "") # Cloud provider or platform (e.g., "AWS EKS", "GCP", "Azure")<br/>      account      = optional(string, "") # Account or environment identifier (e.g., "production", "staging")<br/>      threshold    = optional(string, "") # Threshold value that triggered the alert (e.g., "80%", "100ms")<br/>      metric       = optional(string, "") # Metric name or type being monitored (e.g., "cpu-usage", "response-time")<br/>    }), {})<br/><br/>    # Predefined labels structure for all alerts<br/>    labels = optional(object({<br/>      priority = optional(string, "P2")<br/>      severity = optional(string, "warning")<br/>      env      = optional(string, "")<br/>    }), {})<br/>    rules = optional(<br/>      list(object({                                 # Describes custom alert rules<br/>        name           = string                     # The name of the alert rule<br/>        folder_name    = optional(string, null)     # The folder name for the alert rule, if not set it defaults to var.alerts.folder_name<br/>        no_data_state  = optional(string, "NoData") # Describes what state to enter when the rule's query returns No Data<br/>        exec_err_state = optional(string, "Error")  # Describes what state to enter when the rule's query is invalid and the rule cannot be executed<br/><br/>        labels               = optional(map(any), {})        # Labels help to define matchers in notification policy to control where to send each alert. Can be any key-value pairs<br/>        annotations          = optional(map(string), {})     # Annotations to set to the alert rule. Annotations will be used to customize the alert message in notifications template. Can be any key-value pairs<br/>        group                = optional(string, "custom")    # Grafana alert group name in which the rule will be created/grouped<br/>        datasource           = string                        # Name of the datasource used for the alert<br/>        expr                 = optional(string, null)        # Full expression for the alert<br/>        metric_name          = optional(string, "")          # Prometheus metric name which queries the data for the alert<br/>        metric_function      = optional(string, "")          # Prometheus function used with metric for queries, like rate, sum etc.<br/>        metric_interval      = optional(string, "")          # The time interval with using functions like rate<br/>        settings_mode        = optional(string, "replaceNN") # The mode used in B block, possible values are Strict, replaceNN, dropNN<br/>        settings_replaceWith = optional(number, 0)           # The value by which NaN results of the query will be replaced<br/>        filters              = optional(any, {})             # Filters object to identify each service for alerting<br/>        function             = optional(string, "mean")      # One of Reduce functions which will be used in B block for alerting<br/>        equation             = string                        # The equation in the math expression which compares B blocks value with a number and generates an alert if needed. Possible values: gt, lt, gte, lte, e<br/>        threshold            = number                        # The value against which B blocks are compared in the math expression<br/>    })), [])<br/>    contact_points = optional(object({<br/>      slack = optional(list(object({                                                         # Slack contact points list<br/>        name                    = string                                                     # The name of the contact point<br/>        endpoint_url            = optional(string, "https://slack.com/api/chat.postMessage") # Use this to override the Slack API endpoint URL to send requests to<br/>        icon_emoji              = optional(string, "")                                       # The name of a Slack workspace emoji to use as the bot icon<br/>        icon_url                = optional(string, "")                                       # A URL of an image to use as the bot icon<br/>        recipient               = optional(string, null)                                     # Channel, private group, or IM channel (can be an encoded ID or a name) to send messages to<br/>        text                    = optional(string, "")                                       # Templated content of the message<br/>        title                   = optional(string, "")                                       # Templated title of the message<br/>        token                   = optional(string, "")                                       # A Slack API token,for sending messages directly without the webhook method<br/>        webhook_url             = optional(string, "")                                       # A Slack webhook URL,for sending messages via the webhook method<br/>        username                = optional(string, "")                                       # Username for the bot to use<br/>        disable_resolve_message = optional(bool, false)                                      # Whether to disable sending resolve messages<br/>      })), [])<br/>      opsgenie = optional(list(object({                                                  # OpsGenie contact points list<br/>        name                    = string                                                 # The name of the contact point<br/>        api_key                 = string                                                 # The OpsGenie API key to use<br/>        auto_close              = optional(bool, false)                                  # Whether to auto-close alerts in OpsGenie when they resolve in the Alert manager<br/>        message                 = optional(string, "")                                   # The templated content of the message<br/>        api_url                 = optional(string, "https://api.opsgenie.com/v2/alerts") # Allows customization of the OpsGenie API URL<br/>        disable_resolve_message = optional(bool, false)                                  # Whether to disable sending resolve messages<br/>      })), [])<br/>      teams = optional(list(object({                    # Teams contact points list<br/>        name                    = string                # The name of the contact point<br/>        url                     = string                # The MS Teams Webhook URL to use<br/>        message                 = optional(string, "")  # The templated content of the message<br/>        disable_resolve_message = optional(bool, false) # Whether to disable sending resolve messages<br/>        section_title           = optional(string, "")  # The templated subtitle for each message section.<br/>        title                   = optional(string, "")  # The templated title of the message<br/>      })), [])<br/>      webhook = optional(list(object({                     # Contact points that send notifications to an arbitrary webhook, using the Prometheus webhook format<br/>        name                      = string                 # The name of the contact point<br/>        url                       = string                 # The URL to send webhook requests to<br/>        authorization_credentials = optional(string, null) # Allows a custom authorization scheme - attaches an auth header with this value. Do not use in conjunction with basic auth parameters<br/>        authorization_scheme      = optional(string, null) # Allows a custom authorization scheme - attaches an auth header with this name. Do not use in conjunction with basic auth parameters<br/>        basic_auth_password       = optional(string, null) # The password component of the basic auth credentials to use<br/>        basic_auth_user           = optional(string, null) # The username component of the basic auth credentials to use<br/>        disable_resolve_message   = optional(bool, false)  # Whether to disable sending resolve messages. Defaults to<br/>        settings                  = optional(any, null)    # Additional custom properties to attach to the notifier<br/>      })), [])<br/>    }), null)<br/>    notifications = optional(object({<br/>      contact_point   = optional(string, "Slack")       # The default contact point to route all unmatched notifications to<br/>      group_by        = optional(list(string), ["..."]) # A list of alert labels to group alerts into notifications by<br/>      group_interval  = optional(string, "5m")          # Minimum time interval between two notifications for the same group<br/>      repeat_interval = optional(string, "4h")          # Minimum time interval for re-sending a notification if an alert is still firing<br/><br/>      mute_timing = optional(object({                  # Mute timing config, which will be applied on all policies<br/>        name = optional(string, "Default mute timing") # the name of mute timing<br/>        intervals = optional(list(object({             # the mute timing interval configs<br/>          weekdays      = optional(string, null)<br/>          days_of_month = optional(string, null)<br/>          months        = optional(string, null)<br/>          years         = optional(string, null)<br/>          location      = optional(string, null)<br/>          times = optional(object({<br/>            start = optional(string, "00:00")<br/>            end   = optional(string, "24:59")<br/>          }), null)<br/>        })), [])<br/>      }), null)<br/><br/>      policies = optional(list(object({<br/>        contact_point = optional(string, null) # The contact point to route notifications that match this rule to<br/>        continue      = optional(bool, true)   # Whether to continue matching subsequent rules if an alert matches the current rule. Otherwise, the rule will be 'consumed' by the first policy to match it<br/>        group_by      = optional(list(string), ["..."])<br/><br/>        matchers = optional(list(object({<br/>          label = optional(string, "priority") # The name of the label to match against<br/>          match = optional(string, "=")        # The operator to apply when matching values of the given label. Allowed operators are = for equality, != for negated equality, =~ for regex equality, and !~ for negated regex equality<br/>          value = optional(string, "P1")       # The label value to match against<br/>        })), [])<br/>        policies = optional(list(object({ # sub-policies(there is also possibility to implement also ability for sub.sub.sub-policies, but for not seems existing configs are enough)<br/>          contact_point = optional(string, null)<br/>          continue      = optional(bool, true)<br/>          group_by      = optional(list(string), ["..."])<br/>          mute_timings  = optional(list(string), [])<br/><br/>          matchers = optional(list(object({<br/>            label = optional(string, "priority")<br/>            match = optional(string, "=")<br/>            value = optional(string, "P1")<br/>          })), [])<br/>        })), [])<br/>      })), [])<br/>    }), null)<br/>  })</pre> | `{}` | no |
| <a name="input_application_dashboard"></a> [application\_dashboard](#input\_application\_dashboard) | Dashboard for monitoring applications | <pre>list(object({<br/>    name        = string<br/>    defaults    = optional(any, {})                         # allows to pass/override some general defaults for datasources and widgets<br/>    folder_name = optional(string, "application-dashboard") # the folder name for dashboard<br/>    namespace   = optional(string, "prod")<br/>    rows        = optional(any, [])<br/>    data_source = optional(object({<br/>      uid  = optional(string, "prometheus")<br/>      type = optional(string, "prometheus")<br/>    }), {})<br/>    variables = optional(list(object({ # Allows to define variables to be used in dashboard<br/>      name        = string<br/>      type        = optional(string, "custom")<br/>      hide        = optional(number, 0)<br/>      includeAll  = optional(bool, false)<br/>      multi       = optional(bool, false)<br/>      query       = optional(string, "")<br/>      queryValue  = optional(string, "")<br/>      skipUrlSync = optional(bool, false)<br/>      options = optional(list(object({<br/>        selected = optional(bool, false)<br/>        value    = string<br/>        text     = optional(string, null)<br/>      })), [])<br/>    })), [])<br/>    alerts = optional(any, { enabled = true }) # Allows to configure globally dashboard block/(sla|ingress|service) blocks/widgets related alerts<br/>  }))</pre> | `[]` | no |
| <a name="input_cluster_name"></a> [cluster\_name](#input\_cluster\_name) | name of the eks cluster | `string` | n/a | yes |
| <a name="input_dashboards_json_files"></a> [dashboards\_json\_files](#input\_dashboards\_json\_files) | Json definition of dashboard. For quickly provisioning the dashboards | `list(string)` | `[]` | no |
| <a name="input_deploy_grafana_stack_dashboard"></a> [deploy\_grafana\_stack\_dashboard](#input\_deploy\_grafana\_stack\_dashboard) | Whether to deploy the grafana stack dashboard | `bool` | `true` | no |
| <a name="input_deployment_name"></a> [deployment\_name](#input\_deployment\_name) | n/a | `string` | `"Main Dashboard"` | no |
| <a name="input_grafana"></a> [grafana](#input\_grafana) | Values to construct the values file for Grafana Helm chart | <pre>object({<br/>    enabled          = optional(bool, true)<br/>    namespace        = optional(string, null) # the namespace fallbacks to var.namespace if not specified<br/>    create_namespace = optional(bool, true)   # whether create namespace if not exist<br/>    chart_version    = optional(string, "9.2.9")<br/>    resources = optional(object({<br/>      requests = optional(object({<br/>        cpu    = optional(string, "1")<br/>        memory = optional(string, "2Gi")<br/>      }), {})<br/>      limits = optional(object({<br/>        cpu    = optional(string, "2")<br/>        memory = optional(string, "3Gi")<br/>      }), {})<br/>    }), {})<br/>    database = optional(object({           # configure external(or in helm created) database base storing/persisting grafana data<br/>      enabled       = optional(bool, true) # whether database based persistence is enabled<br/>      create        = optional(bool, true) # whether to create mysql databases or use already existing database<br/>      name          = optional(string, "grafana")<br/>      type          = optional(string, "mysql") # when we set external database we can set any sql compatible one like postgresql or ms sql, but when we create database it supports only mysql and changing this field do not affect<br/>      host          = optional(string, null)    # it will set right host for grafana mysql in case create=true<br/>      user          = optional(string, "grafana")<br/>      password      = optional(string, null)     # if not set it will use var.grafana_admin_password<br/>      root_password = optional(string, null)     # if not set it will use var.grafana_admin_password<br/>      persistence = optional(object({            # allows to configure created(when database.create=true) mysql databases storage/persistence configs<br/>        enabled       = optional(bool, true)     # whether to have created in k8s mysql database with persistence<br/>        size          = optional(string, "20Gi") # the size of primary persistent volume of mysql when creating it<br/>        storage_class = optional(string, "gp2")  # default storage class for the mysql database, TODO: consider switching to gp3 or ever better leave empty to use default storage class<br/>      }), {})<br/>      # the size of primary persistent volume of mysql when creating it<br/>      extra_flags = optional(string, "--skip-log-bin") # allows to set extra flags(whitespace separated) on grafana mysql primary instance, we have by default skip-log-bin flag set to disable bin-logs which overload mysql disc and/but we do not use multi replica mysql here<br/>    }), {})<br/>    persistence = optional(object({ # configure pvc base storing/persisting grafana data(it uses sqlite DB in this mode), NOTE: we use mysql database for data storage by default and no need to enable persistence if DB is set, so that we have persistence disable here by default<br/>      enabled       = optional(bool, false)<br/>      type          = optional(string, "pvc")<br/>      size          = optional(string, "20Gi")<br/>      storage_class = optional(string, "gp2") # TODO: consider switching to gp3 or ever better leave empty to use default storage class<br/>    }), {})<br/>    ingress = optional(object({<br/>      additional_annotations = optional(map(string), {})<br/>      hosts                  = optional(list(string), ["grafana.example.com"])<br/>      path                   = optional(string, "/")<br/>      path_type              = optional(string, "Prefix")<br/>      type                   = optional(string, "alb")<br/>      public                 = optional(bool, true)<br/>      tls_enabled            = optional(bool, true)<br/>      alb_certificate        = optional(string, "")<br/>    }), {})<br/><br/>    service_account = optional(object({<br/>      name        = optional(string, "grafana")<br/>      enable      = optional(bool, true)<br/>      annotations = optional(map(string), {})<br/>    }), {})<br/><br/>    redundancy = optional(object({<br/>      enabled      = optional(bool, false)<br/>      max_replicas = optional(number, 4)<br/>      min_replicas = optional(number, 1)<br/>    }), {})<br/><br/>    datasources = optional(list(map(any)), []) # a list of grafana datasource configurations. Based on the type of the datasource the module will fill in the missing configuration for some supported datasources. Mandatory are name and type fields<br/>    trace_log_mapping = optional(object({<br/>      enabled       = optional(bool, false)<br/>      trace_pattern = optional(string, "trace_id=(\\w+)")<br/>    }), {})<br/><br/>    replicas            = optional(number, 1)<br/>    extra_configs       = optional(any, {}) # allows to pass extra/custom configs to grafana helm chart, this configs will deep-merged with all generated internal configs and can override the default set ones. All available options can be found in for the specified chart version here: https://artifacthub.io/packages/helm/grafana/grafana?modal=values<br/>    mysql_extra_configs = optional(any, {}) # allows to pass extra/custom configs to grafana-mysql created helm chart, this configs will deep-merged with all generated internal configs and can override the default set ones. All available options can be found in for the specified chart version here: https://artifacthub.io/packages/helm/bitnami/mysql?modal=values<br/>    sso_settings = optional(map(object({    # SSO settings for Grafana. Supports OAuth2 providers (gitlab, github, google, azuread, okta, generic_oauth), SAML, and LDAP. The map key should be the provider name, NOTE: that multiple providers can be passed but if a user(email is identifier) got logged in by using one of the providers it may fail to login by using another provider.<br/>      oauth2_settings = optional(object({<br/>        name                       = string                # Display name shown on the login page as "Sign in with...". This is different from the provider name (which is the map key like "gitlab", "github", "google", "azuread", "okta", "generic_oauth", "saml", "ldap"). The provider name determines the OAuth2 endpoints, while this name is just the label shown to users (e.g., "GitLab", "GitHub", "Company SSO")<br/>        client_id                  = string                # The client ID of your OAuth2 application<br/>        client_secret              = string                # The client secret of your OAuth2 application<br/>        auth_url                   = optional(string)      # OAuth2 authorization URL (not needed for built-in providers: gitlab, github, google, azuread, okta)<br/>        token_url                  = optional(string)      # OAuth2 token URL (not needed for built-in providers: gitlab, github, google, azuread, okta)<br/>        api_url                    = optional(string)      # OAuth2 API URL (not needed for built-in providers: gitlab, github, google, azuread, okta)<br/>        allow_sign_up              = optional(bool, true)  # If true, new users can automatically create Grafana accounts on first login<br/>        auto_login                 = optional(bool, false) # If true, automatically logs in users, skipping the login screen<br/>        scopes                     = optional(string)      # Comma or space-separated list of OAuth2 scopes (e.g., "openid email profile" for GitLab)<br/>        allowed_groups             = optional(string)      # Comma or space-separated list of GitLab group names (e.g., "org-1", "org-2", "dev-team"). In GitLab, "group" is the organizational unit (like "organization" in GitHub). User must be a MEMBER of at least one of these groups to log in. This checks GROUP MEMBERSHIP, NOT the user's role within the group (Maintainer/Developer/Guest). For GitHub: organization names. Requires OAuth scope "read_api" for GitLab or "read:org" for GitHub.<br/>        allowed_domains            = optional(string)      # Comma or space-separated list of email domains. User must belong to at least one domain to log in. For GitHub: requires "user:email" scope and the user's email must be verified in GitHub. Email privacy settings in GitHub may prevent this from working.<br/>        role_attribute_path        = optional(string)      # JSONPath expression to map OAuth provider groups to Grafana roles. Checks if user is a member of SPECIFIC groups (not org names). Example: "contains(groups[*], 'grafana-admin') && 'Admin' || contains(groups[*], 'grafana-editor') && 'Editor' || 'Viewer'" means: if user is in "grafana-admin" group → Admin role, if in "grafana-editor" group → Editor role, otherwise → Viewer. These groups (e.g., "grafana-admin", "grafana-editor") must exist in your GitLab/GitHub and users must be added to them. Different from allowed_groups which checks org membership.<br/>        role_attribute_strict      = optional(bool)        # If true, requires role_attribute_path to be set and valid<br/>        allow_assign_grafana_admin = optional(bool)        # If true, allows assigning Grafana Admin role via OAuth<br/>        skip_org_role_sync         = optional(bool)        # If true, skips syncing organization roles from OAuth<br/>      }))<br/>      saml_settings = optional(object({<br/>        name             = string                # Display name shown on the login page as "Sign in with..."<br/>        idp_metadata_url = optional(string)      # URL to the SAML Identity Provider metadata XML file<br/>        allow_sign_up    = optional(bool, true)  # If true, new users can automatically create Grafana accounts on first login<br/>        auto_login       = optional(bool, false) # If true, automatically logs in users, skipping the login screen<br/>      }))<br/>      ldap_settings = optional(object({<br/>        allow_sign_up = optional(bool, true) # If true, new users can automatically create Grafana accounts on first login<br/>        config = object({<br/>          servers = list(object({<br/>            host            = string                # LDAP server hostname or IP address<br/>            port            = optional(number, 389) # LDAP server port (default: 389 for LDAP, 636 for LDAPS)<br/>            search_base_dns = list(string)          # Base DNs to search for users (e.g., ["ou=users,dc=example,dc=com"])<br/>            search_filter   = string                # LDAP search filter to find users (e.g., "(cn=%s)" or "(uid=%s)")<br/>          }))<br/>        })<br/>      }))<br/>    })), {})<br/>  })</pre> | `{}` | no |
| <a name="input_grafana_admin_password"></a> [grafana\_admin\_password](#input\_grafana\_admin\_password) | grafana admin user password | `string` | `""` | no |
| <a name="input_loki_stack"></a> [loki\_stack](#input\_loki\_stack) | Values to pass to loki helm chart | <pre>object({<br/>    enabled          = optional(bool, false)<br/>    namespace        = optional(string, null) # the namespace fallbacks to var.namespace if not specified<br/>    create_namespace = optional(bool, true)   # whether create namespace if not exist<br/><br/>    loki = optional(object({<br/>      chart_version    = optional(string, "6.34.0")       # the loki chart version, NOTE: the helm versions >=6.35.0 bring loki-0 pod crash-loops with default configs, makes ure you test things before helm upgrade to newer versions<br/>      release_name     = optional(string, "loki")         # the loki chart release name<br/>      deploymentMode   = optional(string, "SingleBinary") # we have SingleBinary mode by default, and in this mode distributor, ingester, querier, ... and several other components are within single binary loki app<br/>      replicas         = optional(number, 1)              # number of main loki replicas in SingleBinary mode<br/>      auth_enabled     = optional(bool, false)            # should authentication be enabled<br/>      structuredConfig = optional(any, {})                # this provide structured way to pass the loki all configs that available in https://grafana.com/docs/loki/latest/configure/ , for additional field support here code change may be needed or one can use extra_configs option<br/>      commonConfig = optional(object({                    # for more info check https://grafana.com/docs/loki/latest/configuration/#common_config<br/>        replication_factor = optional(number, 1)          # the number of ingesters to write to and read from.<br/>      }), {})<br/>      resources = optional(object({ # resources of loki in SingleBinary mode<br/>        requests = optional(object({<br/>          cpu    = optional(string, "1000m")<br/>          memory = optional(string, "1000Mi")<br/>        }), {})<br/>        limits = optional(object({<br/>          cpu    = optional(string, "1500m")<br/>          memory = optional(string, "2500Mi")<br/>        }), {})<br/>      }), {})<br/>      serviceAccount = optional(object({ # the service account configs that will be assigned to loki main component<br/>        enable      = optional(bool, true)<br/>        name        = optional(string, "loki")<br/>        annotations = optional(map(string), {})<br/>      }), {})<br/>      monitoring = optional(object({ # monitoring related configs<br/>        serviceMonitor = optional(object({<br/>          enabled = optional(bool, true) # whether service monitor is enabled<br/>        }), {})<br/>      }), {})<br/>      ingress = optional(object({ # allows to have loki service accessible from external<br/>        enabled = optional(bool, false)<br/>        type    = optional(string, "alb")<br/>        public  = optional(bool, true)<br/>        tls = optional(object({<br/>          enabled       = optional(bool, true)<br/>          cert_provider = optional(string, null)<br/>        }), {})<br/>        annotations = optional(map(string), {})<br/>        hosts       = optional(list(string), ["loki.example.com"])<br/>        path        = optional(string, "/")<br/>        path_type   = optional(string, "Prefix")<br/>      }), {})<br/>      schemaConfig = optional(list(object({           # Configures the chunk index schema and where it is stored. for more info check https://grafana.com/docs/loki/latest/configure/#schema_config<br/>        from         = optional(string, "2025-01-01") # defines starting at which date this storage schema will be applied        from         = optional(string, "2025-01-01")<br/>        object_store = optional(string, "s3")<br/>        store        = optional(string, "tsdb")<br/>        schema       = optional(string, "v13")<br/>        index = optional(object({<br/>          prefix = optional(string, "index_")<br/>          period = optional(string, "24h")<br/>        }), {})<br/>      })), [{}])<br/>      limits_config = optional(object({                                   # this allows setting limitations and enabling some features for loki. https://grafana.com/docs/loki/latest/configure/#limits_config<br/>        max_query_length          = optional(string, "7d1h")              # the limit to length of chunk store queries. 0 to disable.<br/>        volume_enabled            = optional(bool, true)                  # enables Loki log-volume index queries what can be used in grafana visualize log volume (LogQL → bytes_over_time)<br/>        allow_structured_metadata = optional(bool, true)                  # allow user to send structured metadata in push payload.<br/>        discover_log_levels       = optional(bool, true)                  # discover and add log levels(detected_level) during ingestion, if not present already.<br/>        deletion_mode             = optional(string, "filter-and-delete") # the Deletion mode, Can be one of 'disabled','filter-only', "filter-and-delete". When set to 'filter-only' or 'filter-and-delete', and if retention_enabled=true in the compactor config, then the log entry deletion API endpoints are available<br/>        retention_period          = optional(string, "360h")              # retention period to apply to stored data, only applies if retention_enabled=true in the compactor config. Must be either 0(disabled) or a multiple of 24h, 360h=15days<br/>      }), {})<br/>      compactor_options = optional(object({ # compactor component options, for retention the compactor must run/configured, in "SingleBinary" mode compactor runs in loki single binary and there is no need for compactor separate component so we need only<br/>        retention_enabled    = optional(bool, true)<br/>        working_directory    = optional(string, "/var/loki/compactor")<br/>        delete_request_store = optional(string, "filesystem")<br/>      }), {})<br/>      persistence = optional(object({ # enable persistent disk and configure<br/>        enabled      = optional(bool, true)<br/>        size         = optional(string, "20Gi")<br/>        storageClass = optional(string, "gp2") # TODO: consider switching to gp3 or ever better leave empty to use default storage class<br/>        selector     = optional(string, null)<br/>        annotations  = optional(any, {})<br/>      }), {})<br/>      storage = optional(any, {}) # the storage where loki will place its data, Loki requires a bucket for chunks and the ruler, if no custom configs passed here we create/use s3 storage default configs internally<br/><br/>      # loki stack other components configs(in SingleBinary mode most of them as separate component are disabled)<br/>      chunksCache = optional(object({            # memcached based cache service which being used for chunks caching and improves loki performance when querying data<br/>        enabled         = optional(bool, true)   # whether enabled, we have this enabled by default, but can be disabled manually<br/>        allocatedMemory = optional(number, 8192) # the memory in MBs we attach to this component, the pods requested memory being calculated based on expression round(allocatedMemory * 1.2)<br/>      }), {})<br/>      resultsCache = optional(object({           # memcached based cache service which being used for chunks caching and improves loki performance when querying data<br/>        enabled         = optional(bool, true)   # whether enabled, we have this enabled by default, but can be disabled manually<br/>        allocatedMemory = optional(number, 1024) # the memory in MBs we attach to this component, the pods requested memory being calculated based on expression round(allocatedMemory * 1.2)<br/>      }), {})<br/>      test           = optional(any, { enabled = false })               # helm tests configs<br/>      lokiCanary     = optional(any, { enabled = false })               # the Loki canary pushes logs to and queries from this loki installation to test that it's working correctly<br/>      ruler          = optional(any, { enabled = false, replicas = 0 }) # the internal loki alerting module, which we do not need as we are going to use grafana alerting mechanism<br/>      compactor      = optional(any, { replicas = 0 })                  # compactor component, in SingleBinary mode this included in loki<br/>      read           = optional(any, { replicas = 0 })                  # read component, in SingleBinary mode this included in loki<br/>      write          = optional(any, { replicas = 0 })                  # write component, in SingleBinary mode this included in loki<br/>      backend        = optional(any, { replicas = 0 })                  # backend component, in SingleBinary mode this included in loki<br/>      ingester       = optional(any, { replicas = 0 })                  # ingester component, in SingleBinary mode this included in loki<br/>      querier        = optional(any, { replicas = 0 })                  # querier component, in SingleBinary mode this included in loki<br/>      queryFrontend  = optional(any, { replicas = 0 })                  # queryFrontend component, in SingleBinary mode this included in loki<br/>      queryScheduler = optional(any, { replicas = 0 })                  # queryScheduler component, in SingleBinary mode this included in loki<br/>      distributor    = optional(any, { replicas = 0 })                  # distributor component, in SingleBinary mode this included in loki<br/>      indexGateway   = optional(any, { replicas = 0 })                  # indexGateway component, in SingleBinary mode this included in loki<br/>      bloomBuilder   = optional(any, { replicas = 0 })                  # bloomBuilder component, in SingleBinary mode this included in loki<br/>      bloomPlanner   = optional(any, { replicas = 0 })                  # bloomPlanner component, in SingleBinary mode this included in loki<br/>      bloomGateway   = optional(any, { replicas = 0 })                  # bloomGateway component, in SingleBinary mode this included in loki<br/><br/>      extra_configs = optional(any, {}) # allows to pass extra/custom configs to loki helm chart, this configs will deep-merged with all generated internal configs and can override the default set ones. All available options can be found in for the specified chart version here: https://artifacthub.io/packages/helm/grafana/loki?modal=values<br/>    }), {})<br/><br/>    send_logs_s3 = optional(object({ # aws s3 bucket configs which will be used as storage for loki<br/>      enable       = optional(bool, true)<br/>      bucket_name  = optional(string, "") # if not passed loki-logs-${var.cluster_name}-${random_string.random.result} format will be used for name<br/>      aws_role_arn = optional(string, "")<br/>    }), {})<br/>    # TODO: the promtail deprecated, consider to have this replaced with for example fluent/fluent-bit<br/>    promtail = optional(object({<br/>      enabled               = optional(bool, true)<br/>      chart_version         = optional(string, "6.17.1")<br/>      log_level             = optional(string, "info")<br/>      server_port           = optional(string, "3101")<br/>      clients               = optional(list(string), [])<br/>      log_format            = optional(string, "logfmt")<br/>      extra_scrape_configs  = optional(list(any), [])<br/>      extra_label_configs   = optional(list(map(string)), [])<br/>      extra_pipeline_stages = optional(any, [])<br/>      ignored_containers    = optional(list(string), [])<br/>      ignored_namespaces    = optional(list(string), [])<br/>      extra_configs         = optional(any, {}) # allows to pass extra/custom configs to promtail helm chart, this configs will deep-merged with all generated internal configs and can override the default set ones. All available options can be found in for the specified chart version here: https://artifacthub.io/packages/helm/grafana/promtail?modal=values<br/>    }), {})<br/>  })</pre> | `{}` | no |
| <a name="input_name_prefix"></a> [name\_prefix](#input\_name\_prefix) | Name Prefix for policy,role ... | `string` | `""` | no |
| <a name="input_namespace"></a> [namespace](#input\_namespace) | n/a | `string` | `"monitoring"` | no |
| <a name="input_prometheus"></a> [prometheus](#input\_prometheus) | values to be used as prometheus's chart values | <pre>object({<br/>    enabled          = optional(bool, true)<br/>    namespace        = optional(string, null) # the namespace fallbacks to var.namespace if not specified<br/>    create_namespace = optional(bool, true)   # whether create namespace if not exist<br/>    chart_version    = optional(string, "75.8.0")<br/>    retention_days   = optional(string, "30d")<br/>    storage_class    = optional(string, "gp2") # TODO: consider switching to gp3 or ever better leave empty to use default storage class<br/>    storage_size     = optional(string, "100Gi")<br/>    access_modes     = optional(list(string), ["ReadWriteOnce"])<br/>    resources = optional(object({<br/>      requests = optional(object({<br/>        cpu    = optional(string, "3")<br/>        memory = optional(string, "4Gi")<br/>      }), {})<br/>      limits = optional(object({<br/>        cpu    = optional(string, "4")<br/>        memory = optional(string, "5Gi")<br/>      }), {})<br/>    }), {})<br/>    ingress = optional(object({<br/>      enabled     = optional(bool, false)<br/>      type        = optional(string, "alb")<br/>      public      = optional(bool, true)<br/>      tls_enabled = optional(bool, true)<br/><br/>      additional_annotations = optional(map(string), {})<br/>      hosts                  = optional(list(string), ["prometheus.example.com"])<br/>      path                   = optional(list(string), ["/"])<br/>      path_type              = optional(string, "Prefix")<br/>    }), {})<br/>    replicas                  = optional(number, 1)<br/>    enable_alertmanager       = optional(bool, true)<br/>    additional_scrape_configs = optional(any, []) # allows to specify additional scrape configs to be added to the prometheus helm chart<br/>    kubelet_metrics = optional(list(string), ["container_cpu_.*", "container_memory_.*", "kube_pod_container_status_.*",<br/>      "kube_pod_container_resource_.*", "container_network_.*", "kube_pod_resource_limit",<br/>      "kube_pod_resource_request", "pod_cpu_usage_seconds_total", "pod_memory_usage_bytes",<br/>      "kubelet_volume_stats.*", "volume_operation_total_seconds.*", "container_fs_.*"]<br/>    ) # allows to specify kubelet metrics to scrape. By default, we scrape the default ones.<br/>    additional_args = optional(list(object({<br/>      name  = string<br/>      value = string<br/>      })), [<br/>      {<br/>        name  = "query.max-concurrency"<br/>        value = "64"<br/>      },<br/>      {<br/>        name  = "query.timeout"<br/>        value = "2m"<br/>      },<br/>      {<br/>        name  = "query.max-samples"<br/>        value = "75000000"<br/>      }<br/>    ])<br/>    extra_configs = optional(any, {}) # allows to pass extra/custom configs to prometheus helm chart, this configs will deep-merged with all generated internal configs and can override the default set ones. All available options can be found in for the specified chart version here: https://artifacthub.io/packages/helm/prometheus-community/prometheus?modal=values<br/>  })</pre> | `{}` | no |
| <a name="input_tempo"></a> [tempo](#input\_tempo) | confgis for tempo deployment | <pre>object({<br/>    enabled                = optional(bool, false)<br/>    namespace              = optional(string, null) # the namespace fallbacks to var.namespace if not specified<br/>    create_namespace       = optional(bool, true)   # whether create namespace if not exist<br/>    chart_version          = optional(string, "1.23.3")<br/>    bucket_name            = optional(string, "")<br/>    enable_service_monitor = optional(bool, true)<br/>    storage = optional(object({<br/>      backend               = optional(string, "s3")<br/>      backend_configuration = optional(map(any), {})<br/>    }), {})<br/>    service_account = optional(object({<br/>      name        = optional(string, "tempo")<br/>      enable      = optional(bool, true)<br/>      annotations = optional(map(string), {})<br/>    }), {})<br/>    metrics_generator = optional(object({<br/>      enabled    = optional(bool, true)<br/>      remote_url = optional(string, "http://prometheus-kube-prometheus-prometheus.monitoring.svc.cluster.local:9090/api/v1/write")<br/>    }))<br/><br/>    persistence = optional(object({<br/>      enabled       = optional(bool, true)<br/>      size          = optional(string, "20Gi")<br/>      storage_class = optional(string, "gp2") # TODO: consider switching to gp3 or ever better leave empty to use default storage class<br/>    }), {})<br/>    extra_configs = optional(any, {}) # allows to pass extra/custom configs to tempo helm chart, this configs will deep-merged with all generated internal configs and can override the default set ones. All available options can be found in for the specified chart version here: https://artifacthub.io/packages/helm/grafana/tempo?modal=values<br/>  })</pre> | `{}` | no |

## Outputs

No outputs.
<!-- END OF PRE-COMMIT-TERRAFORM DOCS HOOK -->
